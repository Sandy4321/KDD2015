{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/simengy/Notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simengy/Data Science/KDD2015\n"
     ]
    }
   ],
   "source": [
    "cd /home/simengy/Data\\ Science/KDD2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "enroll_train = pd.read_csv('data/train/enrollment_train.csv', header=False)\n",
    "log_train = pd.read_csv('data/train/log_train.csv', header=False)\n",
    "label_train = pd.read_csv('data/train/truth_train.csv', header=False)\n",
    "\n",
    "cource_hirach = pd.read_csv('data/object.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120542, 3)\n",
      "(8157277, 5)\n",
      "(120541, 2)\n"
     ]
    }
   ],
   "source": [
    "print enroll_train.shape\n",
    "print log_train.shape\n",
    "print label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollment_id (120542,)\n",
      "username (79186,)\n",
      "course_id (39,)\n"
     ]
    }
   ],
   "source": [
    "for col in enroll_train.columns:\n",
    "\n",
    "    levels = pd.Categorical(enroll_train[col]).categories\n",
    "    print col, levels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enrollment_id (120542,)\n",
      "time (3922167,)\n",
      "source (2,)\n",
      "event (7,)\n",
      "object (5890,)\n"
     ]
    }
   ],
   "source": [
    "for col in log_train.columns:\n",
    "\n",
    "    levels = pd.Categorical(log_train[col]).levels\n",
    "    print col, levels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_id (39,)\n",
      "module_id (26750,)\n",
      "category (15,)\n",
      "children (13192,)\n",
      "start (421,)\n"
     ]
    }
   ],
   "source": [
    "for col in cource_hirach.columns:\n",
    "\n",
    "    levels = pd.Categorical(cource_hirach[col]).levels\n",
    "    print col, levels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79293352469284306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_train.loc[1:100]\n",
    "\n",
    "label_train['0'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "for col in enroll_train.columns:\n",
    "\n",
    "    levels = pd.Categorical(enroll_train[col]).levels\n",
    "    print col, levels.shape\n",
    "\n",
    "    \n",
    "print \n",
    "for col in log_train.columns:\n",
    "\n",
    "    levels = pd.Categorical(log_train[col]).levels\n",
    "    print col, levels.shape\n",
    "    \n",
    "    if col == 'event':\n",
    "        print enc.fit_transform(log_train[col].T.to_dict().values())    \n",
    "    if col == 'object':\n",
    "        print enc.fit_transform(log_train[col].T.to_dict().values())\n",
    "        \n",
    "        \n",
    "        \n",
    "    if col == 'sources':\n",
    "        \n",
    "        pd.core.reshape.get_dummies(log_train[col])\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/simengy/git/xgboost/wrapper/')\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "y_columns = [name for name in train_with_labels.columns if name.startswith('y')]\n",
    "\n",
    "X_numerical_base, X_numerical_meta, X_sparse_base, X_sparse_meta, y_base, y_meta = train_test_split(\n",
    "    X_numerical, \n",
    "    X_sparse, \n",
    "    train_with_labels[y_columns].values,\n",
    "    test_size = 0.5\n",
    ")\n",
    "\n",
    "X_meta = [] \n",
    "X_test_meta = []\n",
    "\n",
    "print \"Build meta\"\n",
    "\n",
    "\n",
    "param = {'bst:max_depth':8, 'bst:eta':0.2, 'silent':0, 'objective':'binary:logistic' }\n",
    "        param['nthread'] = 16\n",
    "        plst = param.items()\n",
    "        #plst += [('eval_metric', 'auc')] # Multiple evals can be handled in this way\n",
    "        plst += [('eval_metric', 'logloss')]\n",
    "        num_round = 100\n",
    "        \n",
    "        dX_base = xgb.DMatrix(X_numerical_base, label = y)\n",
    "        bst = xgb.train(plst, dX_base, num_round)\n",
    "        \n",
    "        dX_num_meta = xgb.DMatrix(X_numerical_meta)\n",
    "        X_meta.append(bst.predict(dX_num_meta))\n",
    "        \n",
    "        dX_test_num = xgb.DMatrix(X_test_numerical)\n",
    "        X_test_meta.append(bst.predict(dX_test_num))\n",
    "        \n",
    "        print i, 'xgboost = ', datetime.now() - t1\n",
    "        t2 = datetime.now()\n",
    "        \n",
    "        logit = LogisticRegression(C=0.01, tol=0.000001)\n",
    "        logit.fit(X_sparse_base, y)\n",
    "        X_meta.append(logit.predict_proba(X_sparse_meta))\n",
    "        X_test_meta.append(logit.predict_proba(X_test_sparse))\n",
    "        \n",
    "        print i, 'logit = ', datetime.now() - t2\n",
    "        \n",
    "X_meta = np.column_stack(X_meta)\n",
    "X_test_meta = np.column_stack(X_test_meta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
